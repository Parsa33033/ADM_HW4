{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7b523ea",
   "metadata": {},
   "source": [
    "# Homework 4 - Hard coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1f852dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ipynb\n",
      "  Downloading ipynb-0.5.1-py3-none-any.whl (6.9 kB)\n",
      "Installing collected packages: ipynb\n",
      "Successfully installed ipynb-0.5.1\n"
     ]
    }
   ],
   "source": [
    "!pip install ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7581f0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting import-ipynb\n",
      "  Downloading import-ipynb-0.1.3.tar.gz (4.0 kB)\n",
      "Building wheels for collected packages: import-ipynb\n",
      "  Building wheel for import-ipynb (setup.py): started\n",
      "  Building wheel for import-ipynb (setup.py): finished with status 'done'\n",
      "  Created wheel for import-ipynb: filename=import_ipynb-0.1.3-py3-none-any.whl size=2975 sha256=400d82a1d217f9336fabe3748eae08741d9fb2cb8ee39380563442d94e900679\n",
      "  Stored in directory: c:\\users\\parsa33033\\appdata\\local\\pip\\cache\\wheels\\06\\7e\\ad\\1cb03e935234186825cefc7e2c8f3451b4f654b5bc72232a7b\n",
      "Successfully built import-ipynb\n",
      "Installing collected packages: import-ipynb\n",
      "Successfully installed import-ipynb-0.1.3\n"
     ]
    }
   ],
   "source": [
    "!pip install import-ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b386b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "id": "2ba684e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import import_ipynb\n",
    "from AudioSignals import *\n",
    "import sys,os\n",
    "import csv\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import scipy as sp\n",
    "import time\n",
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ed9cff",
   "metadata": {},
   "source": [
    "## 1. Implementing your own Shazam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493e2088",
   "metadata": {},
   "source": [
    "### 1.1 Getting your data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5acf144",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|███████▉                                                                       | 141/1413 [06:23<57:42,  2.72s/it]\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"data\"\n",
    "N_TRACKS = 1413\n",
    "\n",
    "if not os.path.exists(data_dir):\n",
    "    os.mkdir(data_dir)\n",
    "\n",
    "def convert_audio(audio_name, audio_path, converted_extention='wav', destination_path=\"data\"):\n",
    "    destination_audio = os.path.join(destination_path, audio_name[:-3] + converted_extention) \n",
    "    if not Path(destination_audio).exists():\n",
    "        subprocess.check_output(f\"ffmpeg -i {audio_path} {destination_audio}\", shell=True)\n",
    "        return destination_audio\n",
    "    return None\n",
    "\n",
    "with open(\"dataset.csv\", \"w\", newline='') as dataset:\n",
    "    writer = csv.writer(dataset)\n",
    "    writer.writerow([\"title\", \"band\", \"album\", \"track\"])\n",
    "    for path, subdirs, files in tqdm(os.walk(\"mp3s-32k\")):\n",
    "        for name in files:\n",
    "            f = path.split('\\\\')           \n",
    "            if len(f) == 3:\n",
    "                mp3_path = os.path.join(path, name)\n",
    "                wav_path = convert_audio(name, mp3_path)\n",
    "                if wav_path:\n",
    "                    writer.writerow([name, f[1], f[2], wav_path])\n",
    "ds = pd.read_csv(\"dataset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67cd4b7b",
   "metadata": {},
   "source": [
    "### 1.2 Fingerprint hashing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 737,
   "id": "e806a790",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_TRACKS = 1413\n",
    "HOP_SIZE = 512\n",
    "DURATION = 30 # TODO: to be tuned!\n",
    "THRESHOLD = 0 # TODO: to be tuned!\n",
    "data_folder = Path(\"data/\")\n",
    "tracks = data_folder.glob(\"*.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 738,
   "id": "dc486cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "hash_sig_num = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 821,
   "id": "3d710192",
   "metadata": {},
   "outputs": [],
   "source": [
    "hash_np = np.vectorize(hash)\n",
    "m = 62352#1245562352367\n",
    "def h1(time, freq):\n",
    "#     return (2**7 * time + 7 * freq) % m\n",
    "    return hash_np(33 * time + freq)\n",
    "def h2(time, freq):\n",
    "#     return (2**12 * time + freq) % m\n",
    "    return hash_np(245 * time + freq)\n",
    "def h(time, freq):\n",
    "    g = []\n",
    "    for i in range(hash_sig_num):\n",
    "        g.append(h1(time, freq) + i * h2(time, freq))\n",
    "    g = np.array(g, dtype=np.int64)\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 822,
   "id": "9af0e083",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_peaks(amplitude):\n",
    "    freq, time = amplitude.shape\n",
    "    peaks = []\n",
    "    for t in range(time):\n",
    "        peaks.extend([[t, f] for f in sp.signal.find_peaks(amplitude[:,t])[0]])\n",
    "    peaks = np.array(peaks)\n",
    "    return peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 823,
   "id": "e2604fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def minhash_signature(amplitude):\n",
    "    peaks = find_peaks(amplitude)\n",
    "    minhash_sig = []\n",
    "    x = h(peaks[:,0], peaks[:,1])\n",
    "    minhash_sig = np.min(h(peaks[:,0], peaks[:,1]), axis=1)\n",
    "    return minhash_sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 824,
   "id": "41dd7609",
   "metadata": {},
   "outputs": [],
   "source": [
    "buckets = dict()\n",
    "buckets_num = 200\n",
    "band_num = 10\n",
    "band_width = hash_sig_num // band_num\n",
    "band = 4 \n",
    "band_start = 4 * band_width\n",
    "band_end = 4 * band_width + band_width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 825,
   "id": "0f0cc5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_file_name = 'dataset.csv'\n",
    "bucket_file_name = 'song_buckets.pkl'\n",
    "minhash_sig_file_name = 'song_minhash_signature.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5025d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(dataset_file_name, 'rb') as dataset:\n",
    "    ds = pd.read_csv(dataset)\n",
    "    with open(minhash_sig_file_name, 'w', newline=\"\") as minhash_dataset:\n",
    "        minhash_writer = csv.writer(minhash_dataset)\n",
    "        minhash_writer.writerow(['index', 'title', 'minhash_signature'])\n",
    "        with open(bucket_file_name, 'wb') as buckets_file:\n",
    "            for idx, row in tqdm(ds.iterrows(), total=ds.shape[0]):\n",
    "                audio = row.track\n",
    "                title = row.title[:-4].split('-')[1]\n",
    "                track, sr, onset_env, peaks = load_audio_picks(audio, DURATION, HOP_SIZE)\n",
    "                fft = librosa.stft(track)\n",
    "                fft_amplitude = librosa.amplitude_to_db(np.abs(fft), ref=np.max)\n",
    "                minhash_sig = minhash_signature(fft_amplitude)\n",
    "                minhash_writer.writerow([idx, title, minhash_sig])\n",
    "                minhash_band = minhash_sig[band_start: band_end]\n",
    "                bucket = (3 * hash(np.sum(minhash_band)) + 7) % buckets_num\n",
    "                if bucket in buckets.keys():\n",
    "                    buckets[bucket].append([idx, minhash_band])\n",
    "                else:\n",
    "                    buckets[bucket] = []\n",
    "                    buckets[bucket].append([idx, minhash_band])\n",
    "                    \n",
    "            pkl.dump(buckets, buckets_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 810,
   "id": "10abefa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(bucket_file_name, 'rb') as d:\n",
    "    buckets = pkl.load(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 820,
   "id": "fb77ad24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   398   3340   6282   9224  12166  15108  18050  20992  23934  26876\n",
      "  29818  32760  35702  38644  41586  44528  47470  50412  53354  56296\n",
      "  59238  62180  65122  68064  71006  73948  76890  79832  82774  85716\n",
      "  88658  91600  94542  97484 100426 103368 106310 109252 112194 115136\n",
      " 118078 121020 123962 126904 129846 132788 135730 138672 141614 144556\n",
      " 147498 150440 153382 156324 159266 162208 165150 168092 171034 173976\n",
      " 176918 179860 182802 185744 188686 191628 194570 197512 200454 203396\n",
      " 206338 209280 212222 215164 218106 221048 223990 226932 229874 232816\n",
      " 235758 238700 241642 244584 247526 250468 253410 256352 259294 262236\n",
      " 265178 268120 271062 274004 276946 279888 282830 285772 288714 291656]\n",
      "9.664488077163696\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "track, sr, onset_env, peaks = load_audio_picks(\"query/track1.wav\", DURATION, HOP_SIZE)\n",
    "fft = librosa.stft(track)\n",
    "fft_amplitude = librosa.amplitude_to_db(np.abs(fft), ref=np.max)\n",
    "t1 = time.time()\n",
    "minhash_sig = minhash_signature(fft_amplitude)\n",
    "minhash_band = minhash_sig[band_start: band_end]\n",
    "bucket = (3 * hash(np.sum(minhash_band)) + 7) % buckets_num\n",
    "print(minhash_sig)\n",
    "\n",
    "# with open(minhash_sig_file_name, 'r', newline=\"\") as minhash_dataset:\n",
    "#     mhds = pd.read_csv(minhash_dataset)\n",
    "#     b = np.array(buckets[bucket])\n",
    "#     print(minhash_band)\n",
    "#     for idx, arr in zip(b[:,0], b[:,1]):\n",
    "#         if str(minhash_band) == str(arr):\n",
    "#             if str(mhds['minhash_signature'][idx]) == str(minhash_sig):\n",
    "#                 print(\"---->\",mhds['title'][idx])\n",
    "#                 print(minhash_sig)\n",
    "#                 print(mhds['minhash_signature'][idx])   \n",
    "t2 = time.time()\n",
    "print(t2 - t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c08e857",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1888bb06",
   "metadata": {},
   "source": [
    "## 2. Grouping songs together!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8def99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "265782b9",
   "metadata": {},
   "source": [
    "### 2.1 Getting your data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f995c925",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ba0b0fb1",
   "metadata": {},
   "source": [
    "### 2.2 Choose your features (variables)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0aded67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0793e72c",
   "metadata": {},
   "source": [
    "### 2.3 Clustering!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd58d13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e527d0cc",
   "metadata": {},
   "source": [
    "### 2.4 Analysing your results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31e36de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "029445bc",
   "metadata": {},
   "source": [
    "## Bonus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e33c09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "369b2cf1",
   "metadata": {},
   "source": [
    "## 3. Algorithmic questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 720,
   "id": "9497ab77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sum_pairs(arr, n, s):\n",
    "    s_set, l = set(), set()\n",
    "    for i in range(n):\n",
    "        s_set.add(arr[i])\n",
    "        if s - arr[i] in s_set:\n",
    "            l.add((arr[i], s - arr[i]))\n",
    "    return l    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 721,
   "id": "d5ed1d56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(-3, 7), (2, 2), (3, 1), (6, -2)}"
      ]
     },
     "execution_count": 721,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = [7, -2, 8, 2, 6, 4, -7, 2, 1, 3, -3]\n",
    "get_sum_pairs(A, len(A), 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7cd214c",
   "metadata": {},
   "source": [
    "Since there is one for loop which goes over all the elements of the array only once, the time complexity is of $O(n)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e92a58b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
